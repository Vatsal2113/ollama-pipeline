#!/usr/bin/env python3
"""
Enhanced Modelfile Generation Script for Ollama Pipeline

This script generates Ollama modelfiles with enhanced configuration options
and better error handling for the fine-tuned models.
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, Optional


def generate_modelfile(
    model_name: str,
    gguf_path: str,
    output_path: str,
    temperature: float = 0.7,
    system_prompt: str = "You are a helpful assistant.",
    top_k: int = 40,
    top_p: float = 0.9,
    repeat_last_n: int = 64,
    repeat_penalty: float = 1.1,
    additional_params: Optional[Dict] = None
) -> str:
    """
    Generate an Ollama modelfile with specified parameters.
    
    Args:
        model_name: Name of the model
        gguf_path: Path to the GGUF file (can be relative or S3 URL)
        output_path: Where to save the modelfile
        temperature: Sampling temperature
        system_prompt: System prompt for the model
        top_k: Top-k sampling parameter
        top_p: Top-p sampling parameter
        repeat_last_n: Repeat penalty last n tokens
        repeat_penalty: Repeat penalty value
        additional_params: Additional parameters to include
    
    Returns:
        Path to the generated modelfile
    """
    
    # Determine the FROM path - if it's a local file, make it relative
    if gguf_path.startswith('s3://') or gguf_path.startswith('http'):
        from_path = gguf_path
    else:
        # Use relative path for local files
        gguf_filename = os.path.basename(gguf_path)
        from_path = f"./{gguf_filename}"
    
    # Build the modelfile content
    modelfile_content = f"""# Ollama Modelfile for {model_name}
# Generated by ollama-pipeline

FROM {from_path}

# Basic parameters
PARAMETER temperature {temperature}
PARAMETER top_k {top_k}
PARAMETER top_p {top_p}
PARAMETER repeat_last_n {repeat_last_n}
PARAMETER repeat_penalty {repeat_penalty}

# System prompt
SYSTEM {system_prompt}
"""

    # Add any additional parameters
    if additional_params:
        modelfile_content += "\n# Additional parameters\n"
        for param, value in additional_params.items():
            modelfile_content += f"PARAMETER {param} {value}\n"
    
    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # Write the modelfile
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(modelfile_content)
    
    print(f"[✓] Modelfile generated: {output_path}")
    return output_path


def load_model_config(config_path: str) -> Dict:
    """Load model configuration from JSON file."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"[WARNING] Config file not found: {config_path}")
        return {}
    except json.JSONDecodeError as e:
        print(f"[ERROR] Invalid JSON in config file: {e}")
        return {}


def main():
    parser = argparse.ArgumentParser(description="Generate Ollama modelfile")
    parser.add_argument("model_name", help="Name of the model")
    parser.add_argument("gguf_path", help="Path to GGUF file")
    parser.add_argument("output_path", help="Output path for modelfile")
    parser.add_argument("--temperature", type=float, default=0.7, help="Temperature parameter")
    parser.add_argument("--system-prompt", default="You are a helpful assistant.", help="System prompt")
    parser.add_argument("--top-k", type=int, default=40, help="Top-k parameter")
    parser.add_argument("--top-p", type=float, default=0.9, help="Top-p parameter")
    parser.add_argument("--repeat-last-n", type=int, default=64, help="Repeat last n tokens")
    parser.add_argument("--repeat-penalty", type=float, default=1.1, help="Repeat penalty")
    parser.add_argument("--config", help="JSON config file with additional parameters")
    
    args = parser.parse_args()
    
    # Load additional config if provided
    additional_params = {}
    if args.config and os.path.exists(args.config):
        config = load_model_config(args.config)
        additional_params = config.get('parameters', {})
    
    try:
        generate_modelfile(
            model_name=args.model_name,
            gguf_path=args.gguf_path,
            output_path=args.output_path,
            temperature=args.temperature,
            system_prompt=args.system_prompt,
            top_k=args.top_k,
            top_p=args.top_p,
            repeat_last_n=args.repeat_last_n,
            repeat_penalty=args.repeat_penalty,
            additional_params=additional_params
        )
        print("[✓] Modelfile generation completed successfully")
        
    except Exception as e:
        print(f"[ERROR] Failed to generate modelfile: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()