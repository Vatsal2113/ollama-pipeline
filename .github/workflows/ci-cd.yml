name: Ollama Lora Pipeline

on:
  push:
    branches:
      - main

jobs:
  build-and-run:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Build Docker image
      # Added --no-cache to force a fresh build and ensure updated build_llama.sh is used
      run: docker build --no-cache -t ollama-lora -f docker/Dockerfile .

    - name: Run fine-tuning pipeline
      run: |
        docker run --rm \
          -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
          -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
          -v ${{ github.workspace }}:/app \
          ollama-lora \
          scripts/pipeline.sh openlm-research/open_llama_3b data/train.jsonl
